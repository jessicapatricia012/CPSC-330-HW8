{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw8.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning\n",
    "\n",
    "## Homework 8: Introduction to Computer vision, Time Series, and Survival Analysis (Lectures 18 to 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## Submission instructions\n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2024W2/blob/main/docs/homework_instructions.md). \n",
    "\n",
    "**You may work in a group on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members).\n",
    "\n",
    "\n",
    "When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission.\n",
    "4. Make sure that the plots and output are rendered properly in your submitted file. \n",
    "5. If the .ipynb file is too big and doesn't render on Gradescope, also upload a pdf or html in addition to the .ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exercise 1: time series prediction\n",
    "\n",
    "In this exercise we'll be looking at a [dataset of avocado prices](https://www.kaggle.com/neuromusic/avocado-prices). You should start by downloading the dataset and storing it under the `data` folder. We will be forcasting average avocado price for the next week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AveragePrice  Total Volume     4046       4225    4770  \\\n",
       "0 2015-12-27          1.33      64236.62  1036.74   54454.85   48.16   \n",
       "1 2015-12-20          1.35      54876.98   674.28   44638.81   58.33   \n",
       "2 2015-12-13          0.93     118220.22   794.70  109149.67  130.50   \n",
       "3 2015-12-06          1.08      78992.15  1132.00   71976.41   72.58   \n",
       "4 2015-11-29          1.28      51039.60   941.48   43838.39   75.78   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  region  \n",
       "0     8696.87     8603.62       93.25          0.0  conventional  2015  Albany  \n",
       "1     9505.56     9408.07       97.49          0.0  conventional  2015  Albany  \n",
       "2     8145.35     8042.21      103.14          0.0  conventional  2015  Albany  \n",
       "3     5811.16     5677.40      133.76          0.0  conventional  2015  Albany  \n",
       "4     6183.95     5986.26      197.69          0.0  conventional  2015  Albany  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/avocado.csv\", parse_dates=[\"Date\"], index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18249, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-01-04 00:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Date\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-03-25 00:00:00')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Date\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the data ranges from the start of 2015 to March 2018 (~2 years ago), for a total of 3.25 years or so. Let's split the data so that we have a 6 months of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = '20170925'\n",
    "df_train = df[df[\"Date\"] <= split_date]\n",
    "df_test  = df[df[\"Date\"] >  split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_train) + len(df_test) == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.1 How many time series? \n",
    "rubric={points:4}\n",
    "\n",
    "In the [Rain in Australia](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package) dataset from lecture demo, we had different measurements for each Location. \n",
    "\n",
    "We want you to consider this for the avocado prices dataset. For which categorical feature(s), if any, do we have separate measurements? Justify your answer by referencing the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.75</td>\n",
       "      <td>27365.89</td>\n",
       "      <td>9307.34</td>\n",
       "      <td>3844.81</td>\n",
       "      <td>615.28</td>\n",
       "      <td>13598.46</td>\n",
       "      <td>13061.10</td>\n",
       "      <td>537.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.49</td>\n",
       "      <td>17723.17</td>\n",
       "      <td>1189.35</td>\n",
       "      <td>15628.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>905.55</td>\n",
       "      <td>905.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2896.72</td>\n",
       "      <td>161.68</td>\n",
       "      <td>206.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2528.08</td>\n",
       "      <td>2528.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>HarrisburgScranton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.52</td>\n",
       "      <td>54956.80</td>\n",
       "      <td>3013.04</td>\n",
       "      <td>35456.88</td>\n",
       "      <td>1561.70</td>\n",
       "      <td>14925.18</td>\n",
       "      <td>11264.80</td>\n",
       "      <td>3660.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Pittsburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1505.12</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1129.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>374.35</td>\n",
       "      <td>186.67</td>\n",
       "      <td>187.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Boise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume     4046      4225     4770  \\\n",
       "51 2015-01-04          1.75      27365.89  9307.34   3844.81   615.28   \n",
       "51 2015-01-04          1.49      17723.17  1189.35  15628.27     0.00   \n",
       "51 2015-01-04          1.68       2896.72   161.68    206.96     0.00   \n",
       "51 2015-01-04          1.52      54956.80  3013.04  35456.88  1561.70   \n",
       "51 2015-01-04          1.64       1505.12     1.27   1129.50     0.00   \n",
       "\n",
       "    Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "51    13598.46    13061.10      537.36          0.0       organic  2015   \n",
       "51      905.55      905.55        0.00          0.0       organic  2015   \n",
       "51     2528.08     2528.08        0.00          0.0       organic  2015   \n",
       "51    14925.18    11264.80     3660.38          0.0  conventional  2015   \n",
       "51      374.35      186.67      187.68          0.0       organic  2015   \n",
       "\n",
       "                region  \n",
       "51           Southeast  \n",
       "51             Chicago  \n",
       "51  HarrisburgScranton  \n",
       "51          Pittsburgh  \n",
       "51               Boise  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"Date\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Date']=='2015-01-04'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we can se that we have multiple rows for the same 'Date'. In fact, we have 108 rows of the same chosen date. We can clearly see that we obviously won't have different measurement for 'type' alone, since we also have multiple rows of the same 'Date' and 'type'. How about 'region'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1373.95</td>\n",
       "      <td>57.42</td>\n",
       "      <td>153.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1162.65</td>\n",
       "      <td>1162.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>1.24</td>\n",
       "      <td>41195.08</td>\n",
       "      <td>1002.85</td>\n",
       "      <td>31640.34</td>\n",
       "      <td>127.12</td>\n",
       "      <td>8424.77</td>\n",
       "      <td>8036.04</td>\n",
       "      <td>388.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1182.56</td>\n",
       "      <td>39.00</td>\n",
       "      <td>305.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>838.44</td>\n",
       "      <td>838.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>44511.28</td>\n",
       "      <td>914.14</td>\n",
       "      <td>31540.32</td>\n",
       "      <td>135.77</td>\n",
       "      <td>11921.05</td>\n",
       "      <td>11651.09</td>\n",
       "      <td>269.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume     4046      4225    4770  \\\n",
       "51 2015-01-04          1.22      40873.28  2819.50  28287.42   49.90   \n",
       "51 2015-01-04          1.79       1373.95    57.42    153.88    0.00   \n",
       "50 2015-01-11          1.24      41195.08  1002.85  31640.34  127.12   \n",
       "50 2015-01-11          1.77       1182.56    39.00    305.12    0.00   \n",
       "49 2015-01-18          1.17      44511.28   914.14  31540.32  135.77   \n",
       "\n",
       "    Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "51     9716.46     9186.93      529.53          0.0  conventional  2015   \n",
       "51     1162.65     1162.65        0.00          0.0       organic  2015   \n",
       "50     8424.77     8036.04      388.73          0.0  conventional  2015   \n",
       "50      838.44      838.44        0.00          0.0       organic  2015   \n",
       "49    11921.05    11651.09      269.96          0.0  conventional  2015   \n",
       "\n",
       "    region  \n",
       "51  Albany  \n",
       "51  Albany  \n",
       "50  Albany  \n",
       "50  Albany  \n",
       "49  Albany  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=[\"region\", \"Date\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['conventional', 'organic'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We have two rows of the same 'Date' with the same 'region', but the 'type's are different (one row for 'conventional' and one for 'organic'). So each row of the dataset correspond to a different combination of 'type', 'region', and 'Date'. I can conclude that we should have separate measurement for each combination of 'region' and 'type'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.2 Equally spaced measurements? \n",
    "rubric={points:4}\n",
    "\n",
    "In the Rain in Australia dataset, the measurements were generally equally spaced but with some exceptions. How about with this dataset? Justify your answer by referencing the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modified code from lecture notes 19\n",
    "def plot_time_spacing_distribution(df, region, type):\n",
    "    \"\"\"\n",
    "    Plots the distribution of time spacing for a given region.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'Location' and 'Date'.\n",
    "        region (str): The region (e.g., location) to analyze.\n",
    "    \"\"\"\n",
    "    # Ensure 'Date' is in datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Filter data for the given region\n",
    "    region_data = df[(df['region'] == region) & (df['type'] == type)]\n",
    "    \n",
    "    if region_data.empty:\n",
    "        print(f\"No data available for region: {region}\")\n",
    "        return\n",
    "    \n",
    "    # Calculate time differences\n",
    "    time_diffs = region_data['Date'].sort_values().diff().dropna()\n",
    "    \n",
    "    # Count the frequency of each time difference\n",
    "    value_counts = time_diffs.value_counts().sort_index()\n",
    "    \n",
    "    # Display value counts\n",
    "    string = (f\"Time spacing counts for {region} and {type}:\\n{value_counts}\\n\")\n",
    "    return string, value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spacing counts for Albany and organic:\n",
      "Date\n",
      "7 days    168\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "string, value_counts = plot_time_spacing_distribution(df, 'Albany', 'organic')\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spacing counts for Albany and conventional:\n",
      "Date\n",
      "7 days    168\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(plot_time_spacing_distribution(df, 'Albany', 'conventional')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "It seems like we have an equally spaced measurement with 7 days for each type of this particular region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spacing counts for WestTexNewMexico and organic:\n",
      "Date\n",
      "7 days     163\n",
      "14 days      1\n",
      "21 days      1\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regions = df['region'].unique()\n",
    "types = df['type'].unique()\n",
    "\n",
    "for region in regions:\n",
    "    for type in types:\n",
    "        string, value_counts1 = plot_time_spacing_distribution(df, region, type)\n",
    "\n",
    "        if not value_counts1.equals(value_counts):\n",
    "            print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all combination of type and region have an equal spacing of 7 days except for WestTexNewMexico and organic, which are mising on some weeks, thus have a 14 and 21 days spacing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.3 Interpreting regions \n",
    "rubric={points:4}\n",
    "\n",
    "In the Rain in Australia dataset, each location was a different place in Australia. For this dataset, look at the names of the regions. Do you think the regions are also all distinct, or are there overlapping regions? Justify your answer by referencing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Albany', 'Atlanta', 'BaltimoreWashington', 'Boise', 'Boston',\n",
       "       'BuffaloRochester', 'California', 'Charlotte', 'Chicago',\n",
       "       'CincinnatiDayton', 'Columbus', 'DallasFtWorth', 'Denver',\n",
       "       'Detroit', 'GrandRapids', 'GreatLakes', 'HarrisburgScranton',\n",
       "       'HartfordSpringfield', 'Houston', 'Indianapolis', 'Jacksonville',\n",
       "       'LasVegas', 'LosAngeles', 'Louisville', 'MiamiFtLauderdale',\n",
       "       'Midsouth', 'Nashville', 'NewOrleansMobile', 'NewYork',\n",
       "       'Northeast', 'NorthernNewEngland', 'Orlando', 'Philadelphia',\n",
       "       'PhoenixTucson', 'Pittsburgh', 'Plains', 'Portland',\n",
       "       'RaleighGreensboro', 'RichmondNorfolk', 'Roanoke', 'Sacramento',\n",
       "       'SanDiego', 'SanFrancisco', 'Seattle', 'SouthCarolina',\n",
       "       'SouthCentral', 'Southeast', 'Spokane', 'StLouis', 'Syracuse',\n",
       "       'Tampa', 'TotalUS', 'West', 'WestTexNewMexico'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes there is obviously an overlap. For example, we have Albany, Atlanta, and New York, which are cities in the New York State located in the north east. Yet we also have the broader Northeast region. Then, we also have TotalUS which combines all data accross the US. Distint regions would be one that only consist of cities, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the entire dataset despite any location-based weirdness uncovered in the previous part.\n",
    "\n",
    "We will be trying to forecast the avocado price. The function below is adapted from [Lecture 19](https://github.com/UBC-CS/cpsc330-2024W2/tree/main/lectures), with some improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lag_feature(df, orig_feature, lag, groupby, new_feature_name=None, clip=False):\n",
    "    \"\"\"\n",
    "    Creates a new feature that's a lagged version of an existing one.\n",
    "    \n",
    "    NOTE: assumes df is already sorted by the time columns and has unique indices.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        The dataset.\n",
    "    orig_feature : str\n",
    "        The column name of the feature we're copying\n",
    "    lag : int\n",
    "        The lag; negative lag means values from the past, positive lag means values from the future\n",
    "    groupby : list\n",
    "        Column(s) to group by in case df contains multiple time series\n",
    "    new_feature_name : str\n",
    "        Override the default name of the newly created column\n",
    "    clip : bool\n",
    "        If True, remove rows with a NaN values for the new feature\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.core.frame.DataFrame\n",
    "        A new dataframe with the additional column added.\n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    if new_feature_name is None:\n",
    "        if lag < 0:\n",
    "            new_feature_name = \"%s_lag%d\" % (orig_feature, -lag)\n",
    "        else:\n",
    "            new_feature_name = \"%s_ahead%d\" % (orig_feature, lag)\n",
    "    \n",
    "    new_df = df.assign(**{new_feature_name : np.nan})\n",
    "    for name, group in new_df.groupby(groupby):        \n",
    "        if lag < 0: # take values from the past\n",
    "            new_df.loc[group.index[-lag:],new_feature_name] = group.iloc[:lag][orig_feature].values\n",
    "        else:       # take values from the future\n",
    "            new_df.loc[group.index[:-lag], new_feature_name] = group.iloc[lag:][orig_feature].values\n",
    "            \n",
    "    if clip:\n",
    "        new_df = new_df.dropna(subset=[new_feature_name])\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first sort our dataframe properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>1.24</td>\n",
       "      <td>41195.08</td>\n",
       "      <td>1002.85</td>\n",
       "      <td>31640.34</td>\n",
       "      <td>127.12</td>\n",
       "      <td>8424.77</td>\n",
       "      <td>8036.04</td>\n",
       "      <td>388.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>44511.28</td>\n",
       "      <td>914.14</td>\n",
       "      <td>31540.32</td>\n",
       "      <td>135.77</td>\n",
       "      <td>11921.05</td>\n",
       "      <td>11651.09</td>\n",
       "      <td>269.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>1.06</td>\n",
       "      <td>45147.50</td>\n",
       "      <td>941.38</td>\n",
       "      <td>33196.16</td>\n",
       "      <td>164.14</td>\n",
       "      <td>10845.82</td>\n",
       "      <td>10103.35</td>\n",
       "      <td>742.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>70873.60</td>\n",
       "      <td>1353.90</td>\n",
       "      <td>60017.20</td>\n",
       "      <td>179.32</td>\n",
       "      <td>9323.18</td>\n",
       "      <td>9170.82</td>\n",
       "      <td>152.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>1.57</td>\n",
       "      <td>18421.24</td>\n",
       "      <td>1974.26</td>\n",
       "      <td>2482.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13964.33</td>\n",
       "      <td>13698.27</td>\n",
       "      <td>266.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>1.54</td>\n",
       "      <td>17393.30</td>\n",
       "      <td>1832.24</td>\n",
       "      <td>1905.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13655.49</td>\n",
       "      <td>13401.93</td>\n",
       "      <td>253.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>1.56</td>\n",
       "      <td>22128.42</td>\n",
       "      <td>2162.67</td>\n",
       "      <td>3194.25</td>\n",
       "      <td>8.93</td>\n",
       "      <td>16762.57</td>\n",
       "      <td>16510.32</td>\n",
       "      <td>252.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>1.56</td>\n",
       "      <td>15896.38</td>\n",
       "      <td>2055.35</td>\n",
       "      <td>1499.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12341.48</td>\n",
       "      <td>12114.81</td>\n",
       "      <td>226.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18248</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.62</td>\n",
       "      <td>15303.40</td>\n",
       "      <td>2325.30</td>\n",
       "      <td>2171.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10806.44</td>\n",
       "      <td>10569.80</td>\n",
       "      <td>236.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AveragePrice  Total Volume     4046      4225    4770  \\\n",
       "0     2015-01-04          1.22      40873.28  2819.50  28287.42   49.90   \n",
       "1     2015-01-11          1.24      41195.08  1002.85  31640.34  127.12   \n",
       "2     2015-01-18          1.17      44511.28   914.14  31540.32  135.77   \n",
       "3     2015-01-25          1.06      45147.50   941.38  33196.16  164.14   \n",
       "4     2015-02-01          0.99      70873.60  1353.90  60017.20  179.32   \n",
       "...          ...           ...           ...      ...       ...     ...   \n",
       "18244 2018-02-25          1.57      18421.24  1974.26   2482.65    0.00   \n",
       "18245 2018-03-04          1.54      17393.30  1832.24   1905.57    0.00   \n",
       "18246 2018-03-11          1.56      22128.42  2162.67   3194.25    8.93   \n",
       "18247 2018-03-18          1.56      15896.38  2055.35   1499.55    0.00   \n",
       "18248 2018-03-25          1.62      15303.40  2325.30   2171.66    0.00   \n",
       "\n",
       "       Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "0         9716.46     9186.93      529.53          0.0  conventional  2015   \n",
       "1         8424.77     8036.04      388.73          0.0  conventional  2015   \n",
       "2        11921.05    11651.09      269.96          0.0  conventional  2015   \n",
       "3        10845.82    10103.35      742.47          0.0  conventional  2015   \n",
       "4         9323.18     9170.82      152.36          0.0  conventional  2015   \n",
       "...           ...         ...         ...          ...           ...   ...   \n",
       "18244    13964.33    13698.27      266.06          0.0       organic  2018   \n",
       "18245    13655.49    13401.93      253.56          0.0       organic  2018   \n",
       "18246    16762.57    16510.32      252.25          0.0       organic  2018   \n",
       "18247    12341.48    12114.81      226.67          0.0       organic  2018   \n",
       "18248    10806.44    10569.80      236.64          0.0       organic  2018   \n",
       "\n",
       "                 region  \n",
       "0                Albany  \n",
       "1                Albany  \n",
       "2                Albany  \n",
       "3                Albany  \n",
       "4                Albany  \n",
       "...                 ...  \n",
       "18244  WestTexNewMexico  \n",
       "18245  WestTexNewMexico  \n",
       "18246  WestTexNewMexico  \n",
       "18247  WestTexNewMexico  \n",
       "18248  WestTexNewMexico  \n",
       "\n",
       "[18249 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sort = df.sort_values(by=[\"region\", \"type\", \"Date\"]).reset_index(drop=True)\n",
    "df_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then call `create_lag_feature`. This creates a new column in the dataset `AveragePriceNextWeek`, which is the following week's `AveragePrice`. We have set `clip=True` which means it will remove rows where the target would be missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>AveragePriceNextWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>1.24</td>\n",
       "      <td>41195.08</td>\n",
       "      <td>1002.85</td>\n",
       "      <td>31640.34</td>\n",
       "      <td>127.12</td>\n",
       "      <td>8424.77</td>\n",
       "      <td>8036.04</td>\n",
       "      <td>388.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>44511.28</td>\n",
       "      <td>914.14</td>\n",
       "      <td>31540.32</td>\n",
       "      <td>135.77</td>\n",
       "      <td>11921.05</td>\n",
       "      <td>11651.09</td>\n",
       "      <td>269.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>1.06</td>\n",
       "      <td>45147.50</td>\n",
       "      <td>941.38</td>\n",
       "      <td>33196.16</td>\n",
       "      <td>164.14</td>\n",
       "      <td>10845.82</td>\n",
       "      <td>10103.35</td>\n",
       "      <td>742.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>70873.60</td>\n",
       "      <td>1353.90</td>\n",
       "      <td>60017.20</td>\n",
       "      <td>179.32</td>\n",
       "      <td>9323.18</td>\n",
       "      <td>9170.82</td>\n",
       "      <td>152.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18243</th>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>1.56</td>\n",
       "      <td>17597.12</td>\n",
       "      <td>1892.05</td>\n",
       "      <td>1928.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13776.71</td>\n",
       "      <td>13553.53</td>\n",
       "      <td>223.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>1.57</td>\n",
       "      <td>18421.24</td>\n",
       "      <td>1974.26</td>\n",
       "      <td>2482.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13964.33</td>\n",
       "      <td>13698.27</td>\n",
       "      <td>266.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>1.54</td>\n",
       "      <td>17393.30</td>\n",
       "      <td>1832.24</td>\n",
       "      <td>1905.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13655.49</td>\n",
       "      <td>13401.93</td>\n",
       "      <td>253.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>1.56</td>\n",
       "      <td>22128.42</td>\n",
       "      <td>2162.67</td>\n",
       "      <td>3194.25</td>\n",
       "      <td>8.93</td>\n",
       "      <td>16762.57</td>\n",
       "      <td>16510.32</td>\n",
       "      <td>252.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>1.56</td>\n",
       "      <td>15896.38</td>\n",
       "      <td>2055.35</td>\n",
       "      <td>1499.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12341.48</td>\n",
       "      <td>12114.81</td>\n",
       "      <td>226.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18141 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AveragePrice  Total Volume     4046      4225    4770  \\\n",
       "0     2015-01-04          1.22      40873.28  2819.50  28287.42   49.90   \n",
       "1     2015-01-11          1.24      41195.08  1002.85  31640.34  127.12   \n",
       "2     2015-01-18          1.17      44511.28   914.14  31540.32  135.77   \n",
       "3     2015-01-25          1.06      45147.50   941.38  33196.16  164.14   \n",
       "4     2015-02-01          0.99      70873.60  1353.90  60017.20  179.32   \n",
       "...          ...           ...           ...      ...       ...     ...   \n",
       "18243 2018-02-18          1.56      17597.12  1892.05   1928.36    0.00   \n",
       "18244 2018-02-25          1.57      18421.24  1974.26   2482.65    0.00   \n",
       "18245 2018-03-04          1.54      17393.30  1832.24   1905.57    0.00   \n",
       "18246 2018-03-11          1.56      22128.42  2162.67   3194.25    8.93   \n",
       "18247 2018-03-18          1.56      15896.38  2055.35   1499.55    0.00   \n",
       "\n",
       "       Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "0         9716.46     9186.93      529.53          0.0  conventional  2015   \n",
       "1         8424.77     8036.04      388.73          0.0  conventional  2015   \n",
       "2        11921.05    11651.09      269.96          0.0  conventional  2015   \n",
       "3        10845.82    10103.35      742.47          0.0  conventional  2015   \n",
       "4         9323.18     9170.82      152.36          0.0  conventional  2015   \n",
       "...           ...         ...         ...          ...           ...   ...   \n",
       "18243    13776.71    13553.53      223.18          0.0       organic  2018   \n",
       "18244    13964.33    13698.27      266.06          0.0       organic  2018   \n",
       "18245    13655.49    13401.93      253.56          0.0       organic  2018   \n",
       "18246    16762.57    16510.32      252.25          0.0       organic  2018   \n",
       "18247    12341.48    12114.81      226.67          0.0       organic  2018   \n",
       "\n",
       "                 region  AveragePriceNextWeek  \n",
       "0                Albany                  1.24  \n",
       "1                Albany                  1.17  \n",
       "2                Albany                  1.06  \n",
       "3                Albany                  0.99  \n",
       "4                Albany                  0.99  \n",
       "...                 ...                   ...  \n",
       "18243  WestTexNewMexico                  1.57  \n",
       "18244  WestTexNewMexico                  1.54  \n",
       "18245  WestTexNewMexico                  1.56  \n",
       "18246  WestTexNewMexico                  1.56  \n",
       "18247  WestTexNewMexico                  1.62  \n",
       "\n",
       "[18141 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hastarget = create_lag_feature(df_sort, \"AveragePrice\", +1, [\"region\", \"type\"], \"AveragePriceNextWeek\", clip=True)\n",
    "df_hastarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to predict `AveragePriceNextWeek`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_hastarget[df_hastarget[\"Date\"] <= split_date]\n",
    "df_test  = df_hastarget[df_hastarget[\"Date\"] >  split_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.4 `AveragePrice` baseline \n",
    "rubric={points}\n",
    "\n",
    "Soon we will want to build some models to forecast the average avocado price a week in advance. Before we start with any ML though, let's try a baseline. Previously we used `DummyClassifier` or `DummyRegressor` as a baseline. This time, we'll do something else as a baseline: we'll assume the price stays the same from this week to next week. So, we'll set our prediction of \"AveragePriceNextWeek\" exactly equal to \"AveragePrice\", assuming no change. That is kind of like saying, \"If it's raining today then I'm guessing it will be raining tomorrow\". This simplistic approach will not get a great score but it's a good starting point for reference. If our model does worse that this, it must not be very good. \n",
    "\n",
    "Using this baseline approach, what $R^2$ do you get on the train and test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snce we are always predicting this week's price, our predicted value is AveragePrice, while the actual value is AveragePriceNextWeek. So the $R^2$ score would be between AveragePriceNextWeek (y_true) and AveragePrice (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285800937261841"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "train_r2 = r2_score(df_train['AveragePriceNextWeek'], df_train['AveragePrice'])\n",
    "train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631780188583048"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_r2 = r2_score(df_test['AveragePriceNextWeek'], df_test['AveragePrice'])\n",
    "test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert not train_r2 is None, \"Are you using the correct variable name?\"\n",
    "assert not test_r2 is None, \"Are you using the correct variable name?\"\n",
    "assert sha1(str(round(train_r2, 3)).encode('utf8')).hexdigest() == 'b1136fe2a8918904393ab6f40bfb3f38eac5fc39', \"Your training score is not correct. Are you using the right features?\"\n",
    "assert sha1(str(round(test_r2, 3)).encode('utf8')).hexdigest() == 'cc24d9a9b567b491a56b42f7adc582f2eefa5907', \"Your test score is not correct. Are you using the right features?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.5 Forecasting average avocado price\n",
    "rubric={points:10}\n",
    "\n",
    "Now that the baseline is done, let's build some models to forecast the average avocado price a week later. Experiment with a few approachs for encoding the date. Justify the decisions you make. Which approach worked best? Report your test score and briefly discuss your results.\n",
    "\n",
    "Benchmark: you should be able to achieve $R^2$ of at least 0.79 on the test set. I got to 0.80, but not beyond that. Let me know if you do better!\n",
    "\n",
    "Note: because we only have 2 splits here, we need to be a bit wary of overfitting on the test set. Try not to test on it a ridiculous number of times. If you are interested in some proper ways of dealing with this, see for example sklearn's [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html), which is like cross-validation for time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.5\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>AveragePriceNextWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>1.24</td>\n",
       "      <td>41195.08</td>\n",
       "      <td>1002.85</td>\n",
       "      <td>31640.34</td>\n",
       "      <td>127.12</td>\n",
       "      <td>8424.77</td>\n",
       "      <td>8036.04</td>\n",
       "      <td>388.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>44511.28</td>\n",
       "      <td>914.14</td>\n",
       "      <td>31540.32</td>\n",
       "      <td>135.77</td>\n",
       "      <td>11921.05</td>\n",
       "      <td>11651.09</td>\n",
       "      <td>269.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>1.06</td>\n",
       "      <td>45147.50</td>\n",
       "      <td>941.38</td>\n",
       "      <td>33196.16</td>\n",
       "      <td>164.14</td>\n",
       "      <td>10845.82</td>\n",
       "      <td>10103.35</td>\n",
       "      <td>742.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>70873.60</td>\n",
       "      <td>1353.90</td>\n",
       "      <td>60017.20</td>\n",
       "      <td>179.32</td>\n",
       "      <td>9323.18</td>\n",
       "      <td>9170.82</td>\n",
       "      <td>152.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AveragePrice  Total Volume     4046      4225    4770  \\\n",
       "0 2015-01-04          1.22      40873.28  2819.50  28287.42   49.90   \n",
       "1 2015-01-11          1.24      41195.08  1002.85  31640.34  127.12   \n",
       "2 2015-01-18          1.17      44511.28   914.14  31540.32  135.77   \n",
       "3 2015-01-25          1.06      45147.50   941.38  33196.16  164.14   \n",
       "4 2015-02-01          0.99      70873.60  1353.90  60017.20  179.32   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "0     9716.46     9186.93      529.53          0.0  conventional  2015   \n",
       "1     8424.77     8036.04      388.73          0.0  conventional  2015   \n",
       "2    11921.05    11651.09      269.96          0.0  conventional  2015   \n",
       "3    10845.82    10103.35      742.47          0.0  conventional  2015   \n",
       "4     9323.18     9170.82      152.36          0.0  conventional  2015   \n",
       "\n",
       "   region  AveragePriceNextWeek  \n",
       "0  Albany                  1.24  \n",
       "1  Albany                  1.17  \n",
       "2  Albany                  1.06  \n",
       "3  Albany                  0.99  \n",
       "4  Albany                  0.99  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15441 entries, 0 to 18222\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Date                  15441 non-null  datetime64[ns]\n",
      " 1   AveragePrice          15441 non-null  float64       \n",
      " 2   Total Volume          15441 non-null  float64       \n",
      " 3   4046                  15441 non-null  float64       \n",
      " 4   4225                  15441 non-null  float64       \n",
      " 5   4770                  15441 non-null  float64       \n",
      " 6   Total Bags            15441 non-null  float64       \n",
      " 7   Small Bags            15441 non-null  float64       \n",
      " 8   Large Bags            15441 non-null  float64       \n",
      " 9   XLarge Bags           15441 non-null  float64       \n",
      " 10  type                  15441 non-null  object        \n",
      " 11  year                  15441 non-null  int64         \n",
      " 12  region                15441 non-null  object        \n",
      " 13  AveragePriceNextWeek  15441 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(10), int64(1), object(2)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "It seems like we have no missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Ridge\n",
    "Let's first try Ridge without encoding Date. Since we have a 'year' feature, we'll use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"AveragePrice\",\n",
    "    \"Total Volume\",\n",
    "    \"4046\",\n",
    "    \"4225\",\n",
    "    \"4770\",\n",
    "    \"Total Bags\",\n",
    "    \"Small Bags\",\n",
    "    \"Large Bags\",\n",
    "    \"XLarge Bags\",\n",
    "]\n",
    "categorical_features = [\n",
    "    \"region\",\n",
    "    \"type\",\n",
    "    \"year\"\n",
    "]\n",
    "drop_features = [\"Date\"]\n",
    "target = [\"AveragePriceNextWeek\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lecture notes 19\n",
    "def preprocess_features(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    numeric_features,\n",
    "    categorical_features,\n",
    "    drop_features,\n",
    "    target\n",
    "):\n",
    "\n",
    "    all_features = set(numeric_features + categorical_features + drop_features + target)\n",
    "    if set(df_train.columns) != all_features:\n",
    "        print(\"Missing columns\", set(df_train.columns) - all_features)\n",
    "        print(\"Extra columns\", all_features - set(df_train.columns))\n",
    "        raise Exception(\"Columns do not match\")\n",
    "\n",
    "    numeric_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"), StandardScaler()\n",
    "    )\n",
    "    categorical_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "        OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "    )\n",
    "\n",
    "    preprocessor = make_column_transformer(\n",
    "        (numeric_transformer, numeric_features),\n",
    "        (categorical_transformer, categorical_features),\n",
    "        (\"drop\", drop_features),\n",
    "    )\n",
    "    preprocessor.fit(df_train)\n",
    "    ohe_feature_names = (\n",
    "        preprocessor.named_transformers_[\"pipeline-2\"]\n",
    "        .named_steps[\"onehotencoder\"]\n",
    "        .get_feature_names_out(categorical_features)\n",
    "        .tolist()\n",
    "    )\n",
    "    new_columns = numeric_features + ohe_feature_names\n",
    "\n",
    "    X_train_enc = pd.DataFrame(\n",
    "        preprocessor.transform(df_train), index=df_train.index, columns=new_columns\n",
    "    )\n",
    "    X_test_enc = pd.DataFrame(\n",
    "        preprocessor.transform(df_test), index=df_test.index, columns=new_columns\n",
    "    )\n",
    "\n",
    "    y_train = df_train[target]\n",
    "    y_test = df_test[target]\n",
    "\n",
    "    return X_train_enc, y_train, X_test_enc, y_test, preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_enc, y_train, X_test_enc, y_test, preprocessor = preprocess_features(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    numeric_features,\n",
    "    categorical_features,\n",
    "    drop_features, target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>region_Albany</th>\n",
       "      <th>...</th>\n",
       "      <th>region_Syracuse</th>\n",
       "      <th>region_Tampa</th>\n",
       "      <th>region_TotalUS</th>\n",
       "      <th>region_West</th>\n",
       "      <th>region_WestTexNewMexico</th>\n",
       "      <th>type_conventional</th>\n",
       "      <th>type_organic</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>year_2016</th>\n",
       "      <th>year_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.432512</td>\n",
       "      <td>-0.234535</td>\n",
       "      <td>-0.229503</td>\n",
       "      <td>-0.222203</td>\n",
       "      <td>-0.214954</td>\n",
       "      <td>-0.232206</td>\n",
       "      <td>-0.229907</td>\n",
       "      <td>-0.223154</td>\n",
       "      <td>-0.172063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.383676</td>\n",
       "      <td>-0.234440</td>\n",
       "      <td>-0.230948</td>\n",
       "      <td>-0.219448</td>\n",
       "      <td>-0.214272</td>\n",
       "      <td>-0.233587</td>\n",
       "      <td>-0.231513</td>\n",
       "      <td>-0.223789</td>\n",
       "      <td>-0.172063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.554604</td>\n",
       "      <td>-0.233469</td>\n",
       "      <td>-0.231018</td>\n",
       "      <td>-0.219530</td>\n",
       "      <td>-0.214196</td>\n",
       "      <td>-0.229850</td>\n",
       "      <td>-0.226469</td>\n",
       "      <td>-0.224325</td>\n",
       "      <td>-0.172063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.823205</td>\n",
       "      <td>-0.233283</td>\n",
       "      <td>-0.230996</td>\n",
       "      <td>-0.218170</td>\n",
       "      <td>-0.213945</td>\n",
       "      <td>-0.230999</td>\n",
       "      <td>-0.228629</td>\n",
       "      <td>-0.222193</td>\n",
       "      <td>-0.172063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.994133</td>\n",
       "      <td>-0.225747</td>\n",
       "      <td>-0.230668</td>\n",
       "      <td>-0.196131</td>\n",
       "      <td>-0.213811</td>\n",
       "      <td>-0.232627</td>\n",
       "      <td>-0.229930</td>\n",
       "      <td>-0.224856</td>\n",
       "      <td>-0.172063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AveragePrice  Total Volume      4046      4225      4770  Total Bags  \\\n",
       "0     -0.432512     -0.234535 -0.229503 -0.222203 -0.214954   -0.232206   \n",
       "1     -0.383676     -0.234440 -0.230948 -0.219448 -0.214272   -0.233587   \n",
       "2     -0.554604     -0.233469 -0.231018 -0.219530 -0.214196   -0.229850   \n",
       "3     -0.823205     -0.233283 -0.230996 -0.218170 -0.213945   -0.230999   \n",
       "4     -0.994133     -0.225747 -0.230668 -0.196131 -0.213811   -0.232627   \n",
       "\n",
       "   Small Bags  Large Bags  XLarge Bags  region_Albany  ...  region_Syracuse  \\\n",
       "0   -0.229907   -0.223154    -0.172063            1.0  ...              0.0   \n",
       "1   -0.231513   -0.223789    -0.172063            1.0  ...              0.0   \n",
       "2   -0.226469   -0.224325    -0.172063            1.0  ...              0.0   \n",
       "3   -0.228629   -0.222193    -0.172063            1.0  ...              0.0   \n",
       "4   -0.229930   -0.224856    -0.172063            1.0  ...              0.0   \n",
       "\n",
       "   region_Tampa  region_TotalUS  region_West  region_WestTexNewMexico  \\\n",
       "0           0.0             0.0          0.0                      0.0   \n",
       "1           0.0             0.0          0.0                      0.0   \n",
       "2           0.0             0.0          0.0                      0.0   \n",
       "3           0.0             0.0          0.0                      0.0   \n",
       "4           0.0             0.0          0.0                      0.0   \n",
       "\n",
       "   type_conventional  type_organic  year_2015  year_2016  year_2017  \n",
       "0                1.0           0.0        1.0        0.0        0.0  \n",
       "1                1.0           0.0        1.0        0.0        0.0  \n",
       "2                1.0           0.0        1.0        0.0        0.0  \n",
       "3                1.0           0.0        1.0        0.0        0.0  \n",
       "4                1.0           0.0        1.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AveragePrice', 'Total Volume', '4046', '4225', '4770', 'Total Bags',\n",
       "       'Small Bags', 'Large Bags', 'XLarge Bags', 'region_Albany',\n",
       "       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',\n",
       "       'region_Boston', 'region_BuffaloRochester', 'region_California',\n",
       "       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',\n",
       "       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',\n",
       "       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',\n",
       "       'region_HarrisburgScranton', 'region_HartfordSpringfield',\n",
       "       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',\n",
       "       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',\n",
       "       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',\n",
       "       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',\n",
       "       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',\n",
       "       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',\n",
       "       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',\n",
       "       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',\n",
       "       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',\n",
       "       'region_SouthCentral', 'region_Southeast', 'region_Spokane',\n",
       "       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',\n",
       "       'region_West', 'region_WestTexNewMexico', 'type_conventional',\n",
       "       'type_organic', 'year_2015', 'year_2016', 'year_2017'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_lr_print_coeff(preprocessor, train_df, y_train, test_df, y_test, X_train_enc):\n",
    "    lr_pipe = make_pipeline(preprocessor, Ridge(random_state=123))\n",
    "    lr_pipe.fit(train_df, y_train)\n",
    "    print(\"Train score: {:.2f}\".format(lr_pipe.score(train_df, y_train)))\n",
    "    print(\"Test score: {:.2f}\".format(lr_pipe.score(test_df, y_test)))\n",
    "    lr_coef = pd.DataFrame(\n",
    "        data=lr_pipe.named_steps[\"ridge\"].coef_.flatten(),\n",
    "        index=pd.DataFrame(X_train_enc).columns,\n",
    "        columns=[\"Coef\"],\n",
    "    )\n",
    "    return lr_coef.sort_values(by=\"Coef\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.85\n",
      "Test score: 0.80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AveragePrice</th>\n",
       "      <td>0.325180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_SanFrancisco</th>\n",
       "      <td>0.091341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_HartfordSpringfield</th>\n",
       "      <td>0.088819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_NewYork</th>\n",
       "      <td>0.070054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_organic</th>\n",
       "      <td>0.051681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Denver</th>\n",
       "      <td>-0.047878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_conventional</th>\n",
       "      <td>-0.051681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_SouthCentral</th>\n",
       "      <td>-0.067115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_DallasFtWorth</th>\n",
       "      <td>-0.068354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Houston</th>\n",
       "      <td>-0.078587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Coef\n",
       "AveragePrice                0.325180\n",
       "region_SanFrancisco         0.091341\n",
       "region_HartfordSpringfield  0.088819\n",
       "region_NewYork              0.070054\n",
       "type_organic                0.051681\n",
       "...                              ...\n",
       "region_Denver              -0.047878\n",
       "type_conventional          -0.051681\n",
       "region_SouthCentral        -0.067115\n",
       "region_DallasFtWorth       -0.068354\n",
       "region_Houston             -0.078587\n",
       "\n",
       "[68 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_lr_print_coeff(preprocessor, df_train, y_train, df_test, y_test, X_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not bad, and it is certainly better than our baseline. We can see from the coefficient that it relies heavily on AveragePrice. Let's try encoding the date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Encoding date as number (day since ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_hastarget[df_hastarget[\"Date\"] <= split_date]\n",
    "df_test  = df_hastarget[df_hastarget[\"Date\"] >  split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>AveragePriceNextWeek</th>\n",
       "      <th>Days_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13858</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>0.94</td>\n",
       "      <td>461607.33</td>\n",
       "      <td>244152.26</td>\n",
       "      <td>165299.33</td>\n",
       "      <td>15302.75</td>\n",
       "      <td>36852.99</td>\n",
       "      <td>30884.29</td>\n",
       "      <td>5595.00</td>\n",
       "      <td>373.7</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>SanDiego</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.02</td>\n",
       "      <td>491738.00</td>\n",
       "      <td>7193.87</td>\n",
       "      <td>396752.18</td>\n",
       "      <td>128.82</td>\n",
       "      <td>87663.13</td>\n",
       "      <td>87406.84</td>\n",
       "      <td>256.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Boston</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13689</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.33</td>\n",
       "      <td>9213.49</td>\n",
       "      <td>3727.52</td>\n",
       "      <td>4327.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1158.45</td>\n",
       "      <td>1158.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13520</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.05</td>\n",
       "      <td>430138.88</td>\n",
       "      <td>110693.69</td>\n",
       "      <td>270107.61</td>\n",
       "      <td>9737.50</td>\n",
       "      <td>39600.08</td>\n",
       "      <td>39600.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AveragePrice  Total Volume       4046       4225      4770  \\\n",
       "0     2015-01-04          1.22      40873.28    2819.50   28287.42     49.90   \n",
       "13858 2015-01-04          0.94     461607.33  244152.26  165299.33  15302.75   \n",
       "1352  2015-01-04          1.02     491738.00    7193.87  396752.18    128.82   \n",
       "13689 2015-01-04          1.33       9213.49    3727.52    4327.52      0.00   \n",
       "13520 2015-01-04          1.05     430138.88  110693.69  270107.61   9737.50   \n",
       "\n",
       "       Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "0         9716.46     9186.93      529.53          0.0  conventional  2015   \n",
       "13858    36852.99    30884.29     5595.00        373.7  conventional  2015   \n",
       "1352     87663.13    87406.84      256.29          0.0  conventional  2015   \n",
       "13689     1158.45     1158.45        0.00          0.0       organic  2015   \n",
       "13520    39600.08    39600.08        0.00          0.0  conventional  2015   \n",
       "\n",
       "           region  AveragePriceNextWeek  Days_since  \n",
       "0          Albany                  1.24           0  \n",
       "13858    SanDiego                  0.82           0  \n",
       "1352       Boston                  1.10           0  \n",
       "13689  Sacramento                  1.27           0  \n",
       "13520  Sacramento                  1.09           0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day = df_train[\"Date\"].min()\n",
    "\n",
    "df_train = df_train.assign(\n",
    "    Days_since=df_train[\"Date\"].apply(lambda x: (x - first_day).days)\n",
    ")\n",
    "df_test = df_test.assign(\n",
    "    Days_since=df_test[\"Date\"].apply(lambda x: (x - first_day).days)\n",
    ")\n",
    "df_train.sort_values(by=\"Date\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AveragePrice', 'Total Volume', '4046', '4225', '4770', 'Total Bags',\n",
       "       'Small Bags', 'Large Bags', 'XLarge Bags', 'Days_since',\n",
       "       'region_Albany', 'region_Atlanta', 'region_BaltimoreWashington',\n",
       "       'region_Boise', 'region_Boston', 'region_BuffaloRochester',\n",
       "       'region_California', 'region_Charlotte', 'region_Chicago',\n",
       "       'region_CincinnatiDayton', 'region_Columbus', 'region_DallasFtWorth',\n",
       "       'region_Denver', 'region_Detroit', 'region_GrandRapids',\n",
       "       'region_GreatLakes', 'region_HarrisburgScranton',\n",
       "       'region_HartfordSpringfield', 'region_Houston', 'region_Indianapolis',\n",
       "       'region_Jacksonville', 'region_LasVegas', 'region_LosAngeles',\n",
       "       'region_Louisville', 'region_MiamiFtLauderdale', 'region_Midsouth',\n",
       "       'region_Nashville', 'region_NewOrleansMobile', 'region_NewYork',\n",
       "       'region_Northeast', 'region_NorthernNewEngland', 'region_Orlando',\n",
       "       'region_Philadelphia', 'region_PhoenixTucson', 'region_Pittsburgh',\n",
       "       'region_Plains', 'region_Portland', 'region_RaleighGreensboro',\n",
       "       'region_RichmondNorfolk', 'region_Roanoke', 'region_Sacramento',\n",
       "       'region_SanDiego', 'region_SanFrancisco', 'region_Seattle',\n",
       "       'region_SouthCarolina', 'region_SouthCentral', 'region_Southeast',\n",
       "       'region_Spokane', 'region_StLouis', 'region_Syracuse', 'region_Tampa',\n",
       "       'region_TotalUS', 'region_West', 'region_WestTexNewMexico',\n",
       "       'type_conventional', 'type_organic', 'year_2015', 'year_2016',\n",
       "       'year_2017'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc, y_train, X_test_enc, y_test, preprocessor = preprocess_features(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    numeric_features + [\"Days_since\"],\n",
    "    categorical_features,\n",
    "    drop_features,\n",
    "    target\n",
    ")\n",
    "X_train_enc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.85\n",
      "Test score: 0.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AveragePrice</th>\n",
       "      <td>0.319366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_SanFrancisco</th>\n",
       "      <td>0.097591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_HartfordSpringfield</th>\n",
       "      <td>0.095290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_NewYork</th>\n",
       "      <td>0.075457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Philadelphia</th>\n",
       "      <td>0.055506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Denver</th>\n",
       "      <td>-0.050518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_conventional</th>\n",
       "      <td>-0.055376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_SouthCentral</th>\n",
       "      <td>-0.072651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_DallasFtWorth</th>\n",
       "      <td>-0.073299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Houston</th>\n",
       "      <td>-0.084002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Coef\n",
       "AveragePrice                0.319366\n",
       "region_SanFrancisco         0.097591\n",
       "region_HartfordSpringfield  0.095290\n",
       "region_NewYork              0.075457\n",
       "region_Philadelphia         0.055506\n",
       "...                              ...\n",
       "region_Denver              -0.050518\n",
       "type_conventional          -0.055376\n",
       "region_SouthCentral        -0.072651\n",
       "region_DallasFtWorth       -0.073299\n",
       "region_Houston             -0.084002\n",
       "\n",
       "[69 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_lr_print_coeff(preprocessor, df_train, y_train, df_test, y_test, X_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results isn't that good. It is even worst than our baseline. This is because the encoded feature is seen as continuous. It doesn't capture any periodical patterns, etc. Let's try One Hot Encoding the month since Avocado prices could be affected by monthly/seasonal patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## OHE of month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_hastarget[df_hastarget[\"Date\"] <= split_date]\n",
    "df_test  = df_hastarget[df_hastarget[\"Date\"] >  split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.assign(Month=df_train[\"Date\"].apply(lambda x: x.month_name()))\n",
    "df_test = df_test.assign(Month=df_test[\"Date\"].apply(lambda x: x.month_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>AveragePriceNextWeek</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.24</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>1.24</td>\n",
       "      <td>41195.08</td>\n",
       "      <td>1002.85</td>\n",
       "      <td>31640.34</td>\n",
       "      <td>127.12</td>\n",
       "      <td>8424.77</td>\n",
       "      <td>8036.04</td>\n",
       "      <td>388.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.17</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>44511.28</td>\n",
       "      <td>914.14</td>\n",
       "      <td>31540.32</td>\n",
       "      <td>135.77</td>\n",
       "      <td>11921.05</td>\n",
       "      <td>11651.09</td>\n",
       "      <td>269.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.06</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>1.06</td>\n",
       "      <td>45147.50</td>\n",
       "      <td>941.38</td>\n",
       "      <td>33196.16</td>\n",
       "      <td>164.14</td>\n",
       "      <td>10845.82</td>\n",
       "      <td>10103.35</td>\n",
       "      <td>742.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>0.99</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>70873.60</td>\n",
       "      <td>1353.90</td>\n",
       "      <td>60017.20</td>\n",
       "      <td>179.32</td>\n",
       "      <td>9323.18</td>\n",
       "      <td>9170.82</td>\n",
       "      <td>152.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>0.99</td>\n",
       "      <td>February</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AveragePrice  Total Volume     4046      4225    4770  \\\n",
       "0 2015-01-04          1.22      40873.28  2819.50  28287.42   49.90   \n",
       "1 2015-01-11          1.24      41195.08  1002.85  31640.34  127.12   \n",
       "2 2015-01-18          1.17      44511.28   914.14  31540.32  135.77   \n",
       "3 2015-01-25          1.06      45147.50   941.38  33196.16  164.14   \n",
       "4 2015-02-01          0.99      70873.60  1353.90  60017.20  179.32   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "0     9716.46     9186.93      529.53          0.0  conventional  2015   \n",
       "1     8424.77     8036.04      388.73          0.0  conventional  2015   \n",
       "2    11921.05    11651.09      269.96          0.0  conventional  2015   \n",
       "3    10845.82    10103.35      742.47          0.0  conventional  2015   \n",
       "4     9323.18     9170.82      152.36          0.0  conventional  2015   \n",
       "\n",
       "   region  AveragePriceNextWeek     Month  \n",
       "0  Albany                  1.24   January  \n",
       "1  Albany                  1.17   January  \n",
       "2  Albany                  1.06   January  \n",
       "3  Albany                  0.99   January  \n",
       "4  Albany                  0.99  February  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AveragePrice', 'Total Volume', '4046', '4225', '4770', 'Total Bags',\n",
       "       'Small Bags', 'Large Bags', 'XLarge Bags', 'region_Albany',\n",
       "       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',\n",
       "       'region_Boston', 'region_BuffaloRochester', 'region_California',\n",
       "       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',\n",
       "       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',\n",
       "       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',\n",
       "       'region_HarrisburgScranton', 'region_HartfordSpringfield',\n",
       "       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',\n",
       "       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',\n",
       "       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',\n",
       "       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',\n",
       "       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',\n",
       "       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',\n",
       "       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',\n",
       "       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',\n",
       "       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',\n",
       "       'region_SouthCentral', 'region_Southeast', 'region_Spokane',\n",
       "       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',\n",
       "       'region_West', 'region_WestTexNewMexico', 'type_conventional',\n",
       "       'type_organic', 'year_2015', 'year_2016', 'year_2017', 'Month_April',\n",
       "       'Month_August', 'Month_December', 'Month_February', 'Month_January',\n",
       "       'Month_July', 'Month_June', 'Month_March', 'Month_May',\n",
       "       'Month_November', 'Month_October', 'Month_September'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc, y_train, X_test_enc, y_test, preprocessor = preprocess_features(\n",
    "    df_train, df_test, \n",
    "    numeric_features, \n",
    "    categorical_features + [\"Month\"], \n",
    "    drop_features,\n",
    "    target\n",
    ")\n",
    "X_train_enc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.85\n",
      "Test score: 0.80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AveragePrice</th>\n",
       "      <td>0.311424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_SanFrancisco</th>\n",
       "      <td>0.106214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_HartfordSpringfield</th>\n",
       "      <td>0.103903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_NewYork</th>\n",
       "      <td>0.081879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Philadelphia</th>\n",
       "      <td>0.060428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Denver</th>\n",
       "      <td>-0.055380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_conventional</th>\n",
       "      <td>-0.060229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_SouthCentral</th>\n",
       "      <td>-0.077472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_DallasFtWorth</th>\n",
       "      <td>-0.079459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Houston</th>\n",
       "      <td>-0.091224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Coef\n",
       "AveragePrice                0.311424\n",
       "region_SanFrancisco         0.106214\n",
       "region_HartfordSpringfield  0.103903\n",
       "region_NewYork              0.081879\n",
       "region_Philadelphia         0.060428\n",
       "...                              ...\n",
       "region_Denver              -0.055380\n",
       "type_conventional          -0.060229\n",
       "region_SouthCentral        -0.077472\n",
       "region_DallasFtWorth       -0.079459\n",
       "region_Houston             -0.091224\n",
       "\n",
       "[80 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_lr_print_coeff(preprocessor, df_train, y_train, df_test, y_test, X_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## OHE of season\n",
    "The results from before is good, but let's try One Hot Encoding the season to capture a broader pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modified from lecture notes\n",
    "def get_season(month):\n",
    "    WINTER_MONTHS = [\"December\", \"January\", \"February\"] \n",
    "    AUTUMN_MONTHS = [\"September\", \"October\", \"November\"]\n",
    "    SUMMER_MONTHS = [\"June\", \"July\", \"August\"]\n",
    "    SPRING_MONTHS = [\"March\", \"April\", \"May\"]\n",
    "    if month in WINTER_MONTHS:\n",
    "        return \"Winter\"\n",
    "    elif month in AUTUMN_MONTHS:\n",
    "        return \"Autumn\"\n",
    "    elif month in SUMMER_MONTHS:\n",
    "        return \"Summer\"\n",
    "    else:\n",
    "        return \"Fall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.assign(Season=df_train[\"Month\"].apply(get_season))\n",
    "df_test = df_test.assign(Season=df_test[\"Month\"].apply(get_season))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>AveragePriceNextWeek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.24</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>1.24</td>\n",
       "      <td>41195.08</td>\n",
       "      <td>1002.85</td>\n",
       "      <td>31640.34</td>\n",
       "      <td>127.12</td>\n",
       "      <td>8424.77</td>\n",
       "      <td>8036.04</td>\n",
       "      <td>388.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.17</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>44511.28</td>\n",
       "      <td>914.14</td>\n",
       "      <td>31540.32</td>\n",
       "      <td>135.77</td>\n",
       "      <td>11921.05</td>\n",
       "      <td>11651.09</td>\n",
       "      <td>269.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.06</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>1.06</td>\n",
       "      <td>45147.50</td>\n",
       "      <td>941.38</td>\n",
       "      <td>33196.16</td>\n",
       "      <td>164.14</td>\n",
       "      <td>10845.82</td>\n",
       "      <td>10103.35</td>\n",
       "      <td>742.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>0.99</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>70873.60</td>\n",
       "      <td>1353.90</td>\n",
       "      <td>60017.20</td>\n",
       "      <td>179.32</td>\n",
       "      <td>9323.18</td>\n",
       "      <td>9170.82</td>\n",
       "      <td>152.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>0.99</td>\n",
       "      <td>February</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18218</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16137.93</td>\n",
       "      <td>2616.96</td>\n",
       "      <td>3672.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9848.01</td>\n",
       "      <td>9816.58</td>\n",
       "      <td>31.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2017</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>2.39</td>\n",
       "      <td>August</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18219</th>\n",
       "      <td>2017-09-03</td>\n",
       "      <td>2.39</td>\n",
       "      <td>7657.47</td>\n",
       "      <td>927.27</td>\n",
       "      <td>4056.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2673.47</td>\n",
       "      <td>2629.18</td>\n",
       "      <td>44.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2017</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>2.38</td>\n",
       "      <td>September</td>\n",
       "      <td>Autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18220</th>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>2.38</td>\n",
       "      <td>11857.31</td>\n",
       "      <td>1562.10</td>\n",
       "      <td>4565.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5729.80</td>\n",
       "      <td>5719.96</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2017</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>2.36</td>\n",
       "      <td>September</td>\n",
       "      <td>Autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18221</th>\n",
       "      <td>2017-09-17</td>\n",
       "      <td>2.36</td>\n",
       "      <td>10464.29</td>\n",
       "      <td>1845.14</td>\n",
       "      <td>2819.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5799.98</td>\n",
       "      <td>5796.65</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2017</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>2.26</td>\n",
       "      <td>September</td>\n",
       "      <td>Autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18222</th>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>2.26</td>\n",
       "      <td>9528.64</td>\n",
       "      <td>1545.34</td>\n",
       "      <td>2234.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5749.07</td>\n",
       "      <td>5722.40</td>\n",
       "      <td>26.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2017</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>2.37</td>\n",
       "      <td>September</td>\n",
       "      <td>Autumn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15441 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AveragePrice  Total Volume     4046      4225    4770  \\\n",
       "0     2015-01-04          1.22      40873.28  2819.50  28287.42   49.90   \n",
       "1     2015-01-11          1.24      41195.08  1002.85  31640.34  127.12   \n",
       "2     2015-01-18          1.17      44511.28   914.14  31540.32  135.77   \n",
       "3     2015-01-25          1.06      45147.50   941.38  33196.16  164.14   \n",
       "4     2015-02-01          0.99      70873.60  1353.90  60017.20  179.32   \n",
       "...          ...           ...           ...      ...       ...     ...   \n",
       "18218 2017-08-27          2.50      16137.93  2616.96   3672.96    0.00   \n",
       "18219 2017-09-03          2.39       7657.47   927.27   4056.73    0.00   \n",
       "18220 2017-09-10          2.38      11857.31  1562.10   4565.41    0.00   \n",
       "18221 2017-09-17          2.36      10464.29  1845.14   2819.17    0.00   \n",
       "18222 2017-09-24          2.26       9528.64  1545.34   2234.23    0.00   \n",
       "\n",
       "       Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "0         9716.46     9186.93      529.53          0.0  conventional  2015   \n",
       "1         8424.77     8036.04      388.73          0.0  conventional  2015   \n",
       "2        11921.05    11651.09      269.96          0.0  conventional  2015   \n",
       "3        10845.82    10103.35      742.47          0.0  conventional  2015   \n",
       "4         9323.18     9170.82      152.36          0.0  conventional  2015   \n",
       "...           ...         ...         ...          ...           ...   ...   \n",
       "18218     9848.01     9816.58       31.43          0.0       organic  2017   \n",
       "18219     2673.47     2629.18       44.29          0.0       organic  2017   \n",
       "18220     5729.80     5719.96        9.84          0.0       organic  2017   \n",
       "18221     5799.98     5796.65        3.33          0.0       organic  2017   \n",
       "18222     5749.07     5722.40       26.67          0.0       organic  2017   \n",
       "\n",
       "                 region  AveragePriceNextWeek      Month  Season  \n",
       "0                Albany                  1.24    January  Winter  \n",
       "1                Albany                  1.17    January  Winter  \n",
       "2                Albany                  1.06    January  Winter  \n",
       "3                Albany                  0.99    January  Winter  \n",
       "4                Albany                  0.99   February  Winter  \n",
       "...                 ...                   ...        ...     ...  \n",
       "18218  WestTexNewMexico                  2.39     August  Summer  \n",
       "18219  WestTexNewMexico                  2.38  September  Autumn  \n",
       "18220  WestTexNewMexico                  2.36  September  Autumn  \n",
       "18221  WestTexNewMexico                  2.26  September  Autumn  \n",
       "18222  WestTexNewMexico                  2.37  September  Autumn  \n",
       "\n",
       "[15441 rows x 16 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AveragePrice', 'Total Volume', '4046', '4225', '4770', 'Total Bags',\n",
       "       'Small Bags', 'Large Bags', 'XLarge Bags', 'region_Albany',\n",
       "       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',\n",
       "       'region_Boston', 'region_BuffaloRochester', 'region_California',\n",
       "       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',\n",
       "       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',\n",
       "       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',\n",
       "       'region_HarrisburgScranton', 'region_HartfordSpringfield',\n",
       "       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',\n",
       "       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',\n",
       "       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',\n",
       "       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',\n",
       "       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',\n",
       "       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',\n",
       "       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',\n",
       "       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',\n",
       "       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',\n",
       "       'region_SouthCentral', 'region_Southeast', 'region_Spokane',\n",
       "       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',\n",
       "       'region_West', 'region_WestTexNewMexico', 'type_conventional',\n",
       "       'type_organic', 'year_2015', 'year_2016', 'year_2017', 'Season_Autumn',\n",
       "       'Season_Fall', 'Season_Summer', 'Season_Winter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc, y_train, X_test_enc, y_test, preprocessor = preprocess_features(\n",
    "    df_train, df_test, \n",
    "    numeric_features, \n",
    "    categorical_features + [\"Season\"], \n",
    "    drop_features + [\"Month\"],\n",
    "    target\n",
    ")\n",
    "X_train_enc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.85\n",
      "Test score: 0.79\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AveragePrice</th>\n",
       "      <td>0.313369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_SanFrancisco</th>\n",
       "      <td>0.104028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_HartfordSpringfield</th>\n",
       "      <td>0.101779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_NewYork</th>\n",
       "      <td>0.080130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Philadelphia</th>\n",
       "      <td>0.059224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Denver</th>\n",
       "      <td>-0.054304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_conventional</th>\n",
       "      <td>-0.059076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_SouthCentral</th>\n",
       "      <td>-0.076319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_DallasFtWorth</th>\n",
       "      <td>-0.077911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_Houston</th>\n",
       "      <td>-0.089481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Coef\n",
       "AveragePrice                0.313369\n",
       "region_SanFrancisco         0.104028\n",
       "region_HartfordSpringfield  0.101779\n",
       "region_NewYork              0.080130\n",
       "region_Philadelphia         0.059224\n",
       "...                              ...\n",
       "region_Denver              -0.054304\n",
       "type_conventional          -0.059076\n",
       "region_SouthCentral        -0.076319\n",
       "region_DallasFtWorth       -0.077911\n",
       "region_Houston             -0.089481\n",
       "\n",
       "[72 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_lr_print_coeff(preprocessor, df_train, y_train, df_test, y_test, X_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The test score gets slightly lower. Maybe the prices have more meaningful variation between individual month than season. Let's add in 'Month' back and drop 'Season' since it is redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.assign(Month=df_train[\"Date\"].apply(lambda x: x.month_name()))\n",
    "df_test = df_test.assign(Month=df_test[\"Date\"].apply(lambda x: x.month_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AveragePrice', 'Total Volume', '4046', '4225', '4770', 'Total Bags',\n",
       "       'Small Bags', 'Large Bags', 'XLarge Bags', 'region_Albany',\n",
       "       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',\n",
       "       'region_Boston', 'region_BuffaloRochester', 'region_California',\n",
       "       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',\n",
       "       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',\n",
       "       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',\n",
       "       'region_HarrisburgScranton', 'region_HartfordSpringfield',\n",
       "       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',\n",
       "       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',\n",
       "       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',\n",
       "       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',\n",
       "       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',\n",
       "       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',\n",
       "       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',\n",
       "       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',\n",
       "       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',\n",
       "       'region_SouthCentral', 'region_Southeast', 'region_Spokane',\n",
       "       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',\n",
       "       'region_West', 'region_WestTexNewMexico', 'type_conventional',\n",
       "       'type_organic', 'year_2015', 'year_2016', 'year_2017', 'Month_April',\n",
       "       'Month_August', 'Month_December', 'Month_February', 'Month_January',\n",
       "       'Month_July', 'Month_June', 'Month_March', 'Month_May',\n",
       "       'Month_November', 'Month_October', 'Month_September'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc, y_train, X_test_enc, y_test, preprocessor = preprocess_features(\n",
    "    df_train, df_test, \n",
    "    numeric_features, \n",
    "    categorical_features + [\"Month\"], \n",
    "    drop_features + [\"Season\"],\n",
    "    target\n",
    ")\n",
    "X_train_enc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.85\n",
      "Test score: 0.80\n"
     ]
    }
   ],
   "source": [
    "coeff_df = score_lr_print_coeff(preprocessor, df_train, y_train, df_test, y_test, X_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month_September</th>\n",
       "      <td>0.052539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_August</th>\n",
       "      <td>0.034566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_July</th>\n",
       "      <td>0.023132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_October</th>\n",
       "      <td>0.023126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_June</th>\n",
       "      <td>0.003469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_May</th>\n",
       "      <td>0.003266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_March</th>\n",
       "      <td>-0.002353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_November</th>\n",
       "      <td>-0.011705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_February</th>\n",
       "      <td>-0.015291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_April</th>\n",
       "      <td>-0.028658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_December</th>\n",
       "      <td>-0.033264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_January</th>\n",
       "      <td>-0.048827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Coef\n",
       "Month_September  0.052539\n",
       "Month_August     0.034566\n",
       "Month_July       0.023132\n",
       "Month_October    0.023126\n",
       "Month_June       0.003469\n",
       "Month_May        0.003266\n",
       "Month_March     -0.002353\n",
       "Month_November  -0.011705\n",
       "Month_February  -0.015291\n",
       "Month_April     -0.028658\n",
       "Month_December  -0.033264\n",
       "Month_January   -0.048827"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df.loc[['Month_April',\n",
    "       'Month_August', 'Month_December', 'Month_February', 'Month_January',\n",
    "       'Month_July', 'Month_June', 'Month_March', 'Month_May',\n",
    "       'Month_November', 'Month_October', 'Month_September']].sort_values(by='Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now back to a test score of 0.80 by encoding month. We can see that the prices are the highest on September and lowest on January.\n",
    "\n",
    "In all attempts, we have a same train score of 0.85. Encoding the date as number results in the lowest test score of 0.75, worse than our baseline. Encoding the season results in a better test score of 0.79. The seasons we encoded must have captured some patterns. The best results come from encoding the month with a test score of 0.80, just slightly higher than encoding seasons. This must be because months capture more patterns than the broader seasonal encoding. However, I noticed that this test score is the same as the very first attempt \"Raw Ridge\", where we didn't do further date encoding and relies only on the year feature. When looking at the final coefficients, we can see that on all attempts the prediction is highly influenced by AveragePrice, followed by regions. The coefficients of our encoded feature, as seen above, are quite low, meaning that our encoded date features doesn't affect the prediction much. So I think it make sense if encoding the date does not significantly improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Short answer questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.1 Time series\n",
    "\n",
    "rubric={points:6}\n",
    "\n",
    "The following questions pertain to Lecture 20 on time series data:\n",
    "\n",
    "1. Sometimes a time series has missing time points or, worse, time points that are unequally spaced in general. Give an example of a real world situation where the time series data would have unequally spaced time points.\n",
    "2. In class we discussed two approaches to using temporal information: encoding the date as one or more features, and creating lagged versions of features. Which of these (one/other/both/neither) two approaches would struggle with unequally spaced time points? Briefly justify your answer.\n",
    "3. When studying time series modeling, we explored several ways to encode date information as a feature for the citibike dataset. When we used time of day as a numeric feature, the Ridge model was not able to capture the periodic pattern. Why? How did we tackle this problem? Briefly explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. An example would be a time series recording the number of victims of a natural disaster, like earthquake, which does not happen on regular intervals.\n",
    "2. The lagged version would struggle more because it depends on the value of previous point in time, and it assumes regular intervals. If the gap in this 'previous point in time' itself is not consistent, the lag column would not make sense and would be misleading. Encoding the date could work better, depending on how it is encoded. For example, encoding the day of the week or the month could still be meaningful because those features might still provide some information, even when the intervals of our data are irregular. \n",
    "3. This is because the numbers could not capture the periodic pattern. In a 3-hour interval, 00.00 comes after 21:00. When we encoded time as integer, Ridge cannot capture that 0 comes after 21. Instead, the linear model sees 0 and 21 as further apart. We tackled this by encoding the time of the day as a categorical feature, then added interaction features (eg. Mon 12:00) with PolynomialFeatures transformer to capture more patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.2 Computer vision \n",
    "rubric={points:6}\n",
    "\n",
    "The following questions pertain to Lecture 19 on multiclass classification and introduction to computer vision. \n",
    "\n",
    "1. How many parameters (coefficients and intercepts) will `sklearn`’s `LogisticRegression()` model learn for a four-class classification problem, assuming that you have 10 features? Briefly explain your answer.\n",
    "2. In Lecture 19, we briefly discussed how neural networks are sort of like `sklearn`'s pipelines, in the sense that they involve multiple sequential transformations of the data, finally resulting in the prediction. Why was this property useful when it came to transfer learning?\n",
    "3. Imagine that you have a small dataset with ~1000 images containing pictures and names of 50 different Computer Science faculty members from UBC. Your goal is to develop a reasonably accurate multi-class classification model for this task. Describe which model/technique you would use and briefly justify your choice in one to three sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The number of coefficient will be $10*4=40$, one for each feature and class. The number of intercept would be 4, one for each class. So the total parameter would be 44.\n",
    "2. Transfer learning is about reusing old models and fine tuning it. Since neural network apply transformation is layers, we could just reuse the early layers and fine tune some of the final steps. This would be easier and more efficient than training an entire model from scratch.\n",
    "3. CNN (e.g. AlexNet) with transfer learning. Since we are dealing with images, it would not be a good idea to flatten them, and CNN can take in images without flattening them. However, training CNN from scratch is way too much work, and our dataset isn't that big, so it would be a great idea to fine tune it on our UBC CS faculty members dataset since it is already trained on famous datasets. We use it as feature extractor to get the feature vectors, then use classifier like Random Forest trained on our classes using the extracted feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 2.3 Survival analysis\n",
    "<hr>\n",
    "\n",
    "rubric={points:6}\n",
    "\n",
    "The following questions pertain to Lecture 21 on survival analysis. We'll consider the use case of customer churn analysis.\n",
    "\n",
    "1. What is the problem with simply labeling customers are \"churned\" or \"not churned\" and using standard supervised learning techniques?\n",
    "2. Consider customer A who just joined last week vs. customer B who has been with the service for a year. Who do you expect will leave the service first: probably customer A, probably customer B, or we don't have enough information to answer? Briefly explain your answer. \n",
    "3. If a customer's survival function is almost flat during a certain period, how do we interpret that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Whether a customer churn or not is time dependent. When we do our standard supervised learning technique, we predict whether a customer would churn or not in the time the data was collected, but customers behavior changes over time, and they can churn at any point of time. It would be more useful if we could determine when they are likely to churn.\n",
    "2. I'd say we don't have enough information. Usually, like the example on the lecture, newer customers are expected to churn first. However, there are a lot of factors that affect how long a customer typically uses the service. It can depend on the type service, or the age of the customer, etc. Without knowing any info about the service or customer A and B, I can't say for sure.\n",
    "3. The probability of them churning is stable on that period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before submitting your assignment, please make sure you have followed all the instructions in the Submission instructions section at the top.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/eva-well-done.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330] *",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "name": "_merged",
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
